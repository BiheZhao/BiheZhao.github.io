
<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="UTF-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>Bihe Zhao personal website</title>
    <link rel="stylesheet" href="https://www.w3schools.com/w3css/4/w3.css">
    <link rel="preconnect" href="https://fonts.googleapis.com">
    <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
    <!--Montserrat font-->
    <link href="https://fonts.googleapis.com/css2?family=Montserrat:ital,wght@0,100;0,200;0,300;0,400;0,500;0,600;0,700;0,800;0,900;1,100;1,200;1,300;1,400;1,500;1,600;1,700;1,800;1,900&display=swap" rel="stylesheet">
    <link rel="stylesheet" href="styles.css" />
    <script src="https://unpkg.com/feather-icons@4.28.0/dist/feather.min.js"></script>
  </head>
  <body>   
    <section>
      <!-- MOBILE NAVIGATION -->
      <div class="w3-container w3-padding-16 w3-border-bottom w3-hide-medium w3-hide-large">
        <!-- <a href="#home" class="w3-bar-item w3-button w3-hover-none">CURRICULUM VITAE</a> -->
        <a href="javascript:void(0)" class="w3-bar-item w3-button w3-right w3-hide-large w3-hide-medium" onclick="toggleNavigation()">&#9776;</a>
      </div>
      <div id="mobile-nav" class="w3-bar-block w3-hide w3-hide-large w3-hide-medium w3-sticky">
        <!-- <a href="#contact" class="w3-bar-item w3-button w3-hover-none w3-border-white w3-bottombar w3-hover-border-teal w3-hover-text-teal w3-right w3-hide-small" style="border-width: 2px !important;" onclick="toggleNavigation()">CONTACT</a>
          <a href="#publications" class="w3-bar-item w3-button w3-hover-none w3-border-white w3-bottombar w3-hover-border-teal w3-hover-text-teal w3-right w3-hide-small" style="border-width: 2px !important;" onclick="toggleNavigation()">PUBLICATIONS</a>
          <a href="#experience" class="w3-bar-item w3-button w3-hover-none w3-border-white w3-bottombar w3-hover-border-teal w3-hover-text-teal w3-right w3-hide-small" style="border-width: 2px !important;" onclick="toggleNavigation()">EXPERIENCE</a>
        <a href="#projects" class="w3-bar-item w3-button w3-hover-none w3-border-white w3-bottombar w3-hover-border-teal w3-hover-text-teal w3-right w3-hide-small" style="border-width: 2px !important;" onclick="toggleNavigation()">PROJECTS</a>
          <a href="#competitions" class="w3-bar-item w3-button w3-hover-none w3-border-white w3-bottombar w3-hover-border-teal w3-hover-text-teal w3-right w3-hide-small" style="border-width: 2px !important;" onclick="toggleNavigation()">COMPETITIONS</a>
          <a href="#awards" class="w3-bar-item w3-button w3-hover-none w3-border-white w3-bottombar w3-hover-border-teal w3-hover-text-teal w3-right w3-hide-small" style="border-width: 2px !important;" onclick="toggleNavigation()">AWARDS</a>
          <a href="#about" class="w3-bar-item w3-button w3-hover-none w3-border-white w3-bottombar w3-hover-border-teal w3-hover-text-teal w3-right w3-hide-small" style="border-width: 2px 
          !important;" onclick="toggleNavigation()">ABOUT</a> -->
        <a href="#about" class="w3-bar-item w3-button w3-center w3-hover-none w3-border-white w3-bottombar w3-hover-border-teal w3-hover-text-teal" onclick="toggleNavigation()">ABOUT</a>
        <a href="#publications" class="w3-bar-item w3-button w3-center w3-hover-none w3-border-white w3-bottombar w3-hover-border-teal w3-hover-text-teal" onclick="toggleNavigation()">PUBLICATIONS</a>
        <a href="#experience" class="w3-bar-item w3-button w3-center w3-hover-none w3-border-white w3-bottombar w3-hover-border-teal w3-hover-text-teal" onclick="toggleNavigation()">EXPERIENCE</a>
        <!-- <a href="#projects" class="w3-bar-item w3-button w3-center w3-hover-none w3-border-white w3-bottombar w3-hover-border-teal w3-hover-text-teal" onclick="toggleNavigation()">PROJECTS</a> -->
        <a href="#competitions" class="w3-bar-item w3-button w3-center w3-hover-none w3-border-white w3-bottombar w3-hover-border-teal w3-hover-text-teal" onclick="toggleNavigation()">COMPETITIONS</a>
        <a href="#awards" class="w3-bar-item w3-button w3-center w3-hover-none w3-border-white w3-bottombar w3-hover-border-teal w3-hover-text-teal" onclick="toggleNavigation()">AWARDS</a>
        <a href="#contact" class="w3-bar-item w3-button w3-center w3-hover-none w3-border-white w3-bottombar w3-hover-border-teal w3-hover-text-teal" onclick="toggleNavigation()">CONTACT</a>
      </div>

      <!-- SOCIAL SECTION -->
      <section class="image-section w3-quarter w3-fixed w3-padding-small">
        <!--IMAGE/AVATAR-->
        <img src="avatar.jpg" class="w3-circle w3-border w3-border-sand" style="border-width: 3px !important;"/>
        <!--SCIAL NETWORK BUTTONS-->
        <div class="links w3-margin-top w3-padding-small">
          
          
          <ul class="w3-ul" style="font-weight: 500;color:white;">
            <h2 style="color:white;">Bihe Zhao</h2>
              <li><a href="mailto:bihe.zhao@cispa.de" style="font-weight: 500;color:white;"> Email </a></li>
              <li><a href="https://github.com/BiheZhao" style="font-weight: 500;color:white;"> GitHub </a></li>
              <!-- <li><a href="https://scholar.google.com/citations?user=l7yrbtYAAAAJ" style="font-weight: 500;color:white;"> Google scholar </a></li> -->
          </ul>
        </div>
        <!--CV DOWNLOAD BUTTON-->
        <!-- <div class="w3-container w3-padding-16">
          <a href="./Bihe_Zhao_CV.pdf" class="w3-amber w3-hover-teal w3-button w3-round-small w3-dark-gray w3-padding-large" target="_blank" download="resume.pdf">
            <i data-feather="arrow-down" style="vertical-align: -0.35em;"></i>
            <span class="w3-margin-left download-text">DOWNLOAD CV</span>
          </a>
        </div> -->
      </section>

      <!--CV CONTENT SECTION-->
      <section class="w3-threequarter w3-padding-large w3-right">
        <!--DESKTOP NAVIGATION-->
        <div class="w3-container w3-padding-large w3-border-bottom w3-hide-small">
          <!-- <a href="#home" class="w3-bar-item w3-button w3-hover-none w3-border-white w3-bottombar w3-hover-border-teal">CURRICULUM VITAE</a> -->
          <a href="#about" class="w3-bar-item w3-button w3-hover-none w3-border-white w3-bottombar w3-hover-border-teal w3-hover-text-teal w3-right w3-hide-small" style="border-width: 2px !important;" onclick="toggleNavigation()">ABOUT</a>
          <a href="#publications" class="w3-bar-item w3-button w3-hover-none w3-border-white w3-bottombar w3-hover-border-teal w3-hover-text-teal w3-right w3-hide-small" style="border-width: 2px !important;" onclick="toggleNavigation()">PUBLICATIONS</a>
          <a href="#experience" class="w3-bar-item w3-button w3-hover-none w3-border-white w3-bottombar w3-hover-border-teal w3-hover-text-teal w3-right w3-hide-small" style="border-width: 2px !important;" onclick="toggleNavigation()">EXPERIENCE</a>
          <!-- <a href="#education" class="w3-bar-item w3-button w3-hover-none w3-border-white w3-bottombar w3-hover-border-teal w3-hover-text-teal w3-right w3-hide-small" style="border-width: 2px !important;" onclick="toggleNavigation()">EDUCATION</a> -->
          <!-- <a href="#projects" class="w3-bar-item w3-button w3-hover-none w3-border-white w3-bottombar w3-hover-border-teal w3-hover-text-teal w3-right w3-hide-small" style="border-width: 2px !important;" onclick="toggleNavigation()">PROJECTS</a> -->
          <a href="#competitions" class="w3-bar-item w3-button w3-hover-none w3-border-white w3-bottombar w3-hover-border-teal w3-hover-text-teal w3-right w3-hide-small" style="border-width: 2px !important;" onclick="toggleNavigation()">COMPETITIONS</a>
          <a href="#awards" class="w3-bar-item w3-button w3-hover-none w3-border-white w3-bottombar w3-hover-border-teal w3-hover-text-teal w3-right w3-hide-small" style="border-width: 2px !important;" onclick="toggleNavigation()">AWARDS</a>
          <a href="#contact" class="w3-bar-item w3-button w3-hover-none w3-border-white w3-bottombar w3-hover-border-teal w3-hover-text-teal w3-right w3-hide-small" style="border-width: 2px !important;" onclick="toggleNavigation()">CONTACT</a>        
        </div>
        <!-- <div class="content-container w3-margin-top-2"> -->
          <!-- HOME SECTION
          <div id="" class="home w3-container w3-margin-top-4 w3-cursive" align="w3-center">
            <!-- <p style="font-style: italic; font-size:x-large;">"The mind is the limit. When you face your struggles, you overcome them."</p> -->
            <!-- <h2>Bihe Zhao</h2>
            <p></p>
          </div> -->
          <!--ABOUT SECTION-->
          <div id="about" class="w3-container w3-margin-bottom-2 w3-cursive w3-large">
            <h2 class="w3-border-bottom w3-border-teal" style="border-width: 3px !important;">ABOUT</h2>
            <p class="w3-margin-top-2"> 
              I am a Ph.D. student at CISPA Helmholtz Center for Information Security, co-supervised by  <a href="https://adam-dziedzic.com/">Prof. Adam Dziedzic</a> and <a href="https://franziska-boenisch.de/">Prof. Franziska Boenisch</a>.
              Before starting my Ph.D. at CISPA, I was a Master student at School of Cyber Science and Technology of Beihang University, co-advised by <a href="https://scholar.google.com/citations?user=T-P6M5kAAAAJ&hl=en">Prof. Zhenyu Guan</a> and <a href="https://sbian3.github.io/">Prof. Song Bian</a>.
              I received my bachelor degree at School of Cyber Science and Technology of Beihang University.
            </p>
            <p class=""> 
              My research interest lies in privacy and security of machine learning models.
            </p>
            <p class=""> 
              Email: <a href="mailto:bihe.zhao@cispa.de" style="font-weight: 500;">bihe.zhao@cispa.de</a>
            </p>
          </div>

          <!--EDUCATION-->
          <!-- <div id="education" class="w3-container w3-margin-top-20-percent w3-cursive">
            <h2 class="w3-border-bottom w3-border-teal" style="border-width: 3px !important;">Education</h2>
            <div class="w3-container w3-margin-top-2 w3-cursive">
              <div class="">
                  <h4>College diploma, College of management, Houston</h4>
                  <p>October 2008 - July 2013 </p>
                  <h4>Highschool diploma, XYZ Highschool, Houston</h4>
                  <p>October 2004 - July 2008 </p>
              </div>
            </div>
          </div> -->

          <!--PUBLICATIONS-->
          <div id="publications" class="w3-container w3-margin-bottom-2 w3-cursive">
            <h2 class="w3-border-bottom w3-border-teal" style="border-width: 3px !important;">PUBLICATIONS</h2>
            <div class="w3-container w3-margin-top-2 w3-cursive">
              <div class="">
                
                  <h4>Unlocking Post-hoc Dataset Inference with Synthetic Data</h4>
                  <p> <b>Bihe Zhao</b>, Pratyush Maini, Franziska Boenisch, Adam Dziedzic</p>
                  <p>ICML 2025</p>
                  <p>
                    [<a href="https://arxiv.org/abs/2506.15271" style="font-weight: 500;">Paper</a>]
                    [<a href="https://github.com/sprintml/PostHocDatasetInference" style="font-weight: 500;">Code</a>]</p>
                  <ul class="w3-ul" style="font-weight: 500;">
                    <li>The remarkable capabilities of Large Language Models (LLMs) can be mainly attributed to their massive training datasets, which are often scraped from the internet without respecting data owners' intellectual property rights. Dataset Inference (DI) offers a potential remedy by identifying whether a suspect dataset was used in training, thereby enabling data owners to verify unauthorized use. However, existing DI methods require a private set-known to be absent from training-that closely matches the compromised dataset's distribution. Such in-distribution, held-out data is rarely available in practice, severely limiting the applicability of DI. In this work, we address this challenge by synthetically generating the required held-out set. Our approach tackles two key obstacles: (1) creating high-quality, diverse synthetic data that accurately reflects the original distribution, which we achieve via a data generator trained on a carefully designed suffix-based completion task, and (2) bridging likelihood gaps between real and synthetic data, which is realized through post-hoc calibration. Extensive experiments on diverse text datasets show that using our generated data as a held-out set enables DI to detect the original training sets with high confidence, while maintaining a low false positive rate. This result empowers copyright owners to make legitimate claims on data usage and demonstrates our method's reliability for real-world litigations.</li>
                  </ul>

                  <h4>BitMark for Infinity: Watermarking Bitwise Autoregressive Image Generative Models</h4>
                  <p>Louis Kerner, Michel Meintz, <b>Bihe Zhao</b>, Franziska Boenisch, Adam Dziedzic</p>
                  <p>NeurIPS 2025</p>
                  <p>
                    [<a href="https://arxiv.org/abs/2506.21209" style="font-weight: 500;">Paper</a>]
                    <!-- [<a href="https://github.com/BiheZhao/NAFID" style="font-weight: 500;">Code</a>]</p> -->
                  <ul class="w3-ul" style="font-weight: 500;">
                    <li>State-of-the-art text-to-image models like Infinity generate photorealistic images at an unprecedented speed. These models operate in a bitwise autoregressive manner over a discrete set of tokens that is practically infinite in size. However, their impressive generative power comes with a growing risk: as their outputs increasingly populate the Internet, they are likely to be scraped and reused as training data-potentially by the very same models. This phenomenon has been shown to lead to model collapse, where repeated training on generated content, especially from the models' own previous versions, causes a gradual degradation in performance. A promising mitigation strategy is watermarking, which embeds human-imperceptible yet detectable signals into generated images-enabling the identification of generated content. In this work, we introduce BitMark, a robust bitwise watermarking framework for Infinity. Our method embeds a watermark directly at the bit level of the token stream across multiple scales (also referred to as resolutions) during Infinity's image generation process. Our bitwise watermark subtly influences the bits to preserve visual fidelity and generation speed while remaining robust against a spectrum of removal techniques. Furthermore, it exhibits high radioactivity, i.e., when watermarked generated images are used to train another image generative model, this second model's outputs will also carry the watermark. The radioactive traces remain detectable even when only fine-tuning diffusion or image autoregressive models on images watermarked with our BitMark. Overall, our approach provides a principled step toward preventing model collapse in image generative models by enabling reliable detection of generated outputs.</li>
                  </ul>
                  <!-- <h4>SEEKER: Query-Efficient Model Extraction via Semi-Supervised Public Knowledge Transfer</h4>
                  <p><b>Bihe Zhao</b>, Zhenyu Guan, Junpeng Jing, Yanting Zhang, Xianglun Leng, Song Bian</p>
                  <ul class="w3-ul" style="font-weight: 500;">
                    <li>
                      Model extraction attacks against Deep Neural Networks (DNN) aim at extracting DNN models without white-box access to the model internals and the training datasets. Currently, most existing model extraction methods require an excessive number of queries (up to millions) to reproduce a useful substitute model, and can be impractical in real-world scenarios. In this work, we propose SEEKER, a two-stage query-efficient model extraction framework that consists of an offline stage and an online stage. First, by using our proposed augmentation invariant unsupervised training scheme, the substitute model is trained to learn generalizable feature representations from the unannotated public dataset. Then, during the online stage, we design an aggregated query generator to craft information-rich queries merging multiple input data in the unannotated public datasets. By conducting thorough experiments, we show that our method can reduce the query budget by more than 50× for attaining the same level of attack success rate when compared to the state-of-the-art model extraction attacks. Additionally, SEEKER is able to achieve as high as 93.97% prediction accuracy while retaining high query-efficiency. In terms of stealthiness, our attack demonstrates the capability of bypassing distribution-based attack detection mechanisms.
                    </li>
                  </ul> -->
        
                  <h4>New Finding and Unified Framework for Fake Image Detection</h4>
                  <p>Xin Deng*, <b>Bihe Zhao</b>*, Zhenyu Guan, Mai Xu</p>
                  <p>IEEE Signal Processing Letters</p>
                  <p>
                    [<a href="https://ieeexplore.ieee.org/document/10041767" style="font-weight: 500;">Paper</a>]
                    [<a href="https://github.com/BiheZhao/NAFID" style="font-weight: 500;">Code</a>]</p>
                  <ul class="w3-ul" style="font-weight: 500;">
                    <li>Recently, fake face images generated by generative adversarial network (GAN) have been widely spread in social networks, raising serious social concerns and security risks. 
                      To identify the fake images, the top priority is to find what properties make the fake images different from the real images. In this letter, we reveal an important observation about real/fake images, i.e., the GAN generated fake images contain stronger non-local self-similarity than the real images. 
                      Motivated by this observation, we propose a simple yet effective non-local attention based fake image detection network, namely NAFID, to distinguish GAN generated fake images from real images. Specifically, we develop a non-local feature extraction (NFE) module to extract the non-local features of the real/fake images, followed by a multi-stage classification module to distinguish the images with the extracted non-local features. Experimental results on various datasets demonstrate the superiority of our NAFID over state-of-the-art (SOTA) face forgery detection methods. 
                      More importantly, since the NFE module is independent from classification, we can plug it into any other forgery detection models. The results show that the NFE module can consistently improve the detection accuracy of other models, which verifies the universality of the proposed method.
                    </li>
                  </ul>

              </div>
            </div>
          </div>

          <!--EXPERIENCE-->
          <div id="experience" class="w3-container w3-container w3-margin-bottom-2 w3-cursive">
            <h2 class="w3-border-bottom w3-border-teal" style="border-width: 3px !important;">EXPERIENCE</h2>
            <div class="w3-container w3-margin-top-2 w3-cursive">

              <!--EMPLOYMENT HISTORY SECTION-->
              <!-- <h3 class="w3-border-teal">Professional Experience</h3> -->
              <div class="">
                <h4>Research Assistant at Agency for Science, Technology and Research (A*STAR)</h4>
                <p>07/2023 - 11/2023</p>
                <ul class="w3-ul" style="font-weight: 500;">
                  <li>Proposed a neural radiance field (NeRF) editing scheme that enables drag-style operations on the NeRF scene under user specification.</li>
                  <!-- <li>Designed an augmentation invariant unsupervised training scheme to effectively extract information from public datasets</li>
                  <li>Proposed an aggregated query generator based on multi-input autoencoder to craft information-extracting queries</li> -->
                  <li>Designed a matching algorithm to enhance multi-view consistency for the edited NeRF scene.</li>
                  <li>Developed a generative model to edit the NeRF scene under the supervision of correspondence across multi views.</li>
                </ul>
              </div>
              <div class="">
                <h4>Research Intern at SenseTime Technology</h4>
                <p>01/2022 - 04/2023</p>
                <ul class="w3-ul" style="font-weight: 500;">
                  <li>Proposed a query-efficient model extraction attack based on public datasets that outperforms state-of-the-art model extraction attacks by a large margin.</li>
                  <!-- <li>Designed an augmentation invariant unsupervised training scheme to effectively extract information from public datasets</li>
                  <li>Proposed an aggregated query generator based on multi-input autoencoder to craft information-extracting queries</li> -->
                  <li>Revealed an observation for face forgery detection and designed a unified detection framework based on the finding.</li>
                  <li>Implemented both projects with Pytorch.</li>
                </ul>
              </div>
              <div class="">
                <h4>Backend Development Intern at ByteDance Technology</h4>
                <p>08/2020 - 01/2020 </p>
                <ul class="w3-ul" style="font-weight: 500;">
                  <li>Assisted in the development of data annotation and management platform</li>
                  <li>Developed and improved an alarm center that has more than 20,000 rules to detect unusual data traffic</li>
                  <li>Wrote more than 5,000 lines of code with Go</li>
                </ul>
              </div>
            </div>
          </div>


          <!--COMPETITIONS-->
          <div id="competitions" class="w3-container w3-container w3-margin-bottom-2 w3-cursive">
            <h2 class="w3-border-bottom w3-border-teal" style="border-width: 3px !important;">COMPETITIONS</h2>
            <div class="w3-container w3-margin-top-2 w3-cursive">
              <div class="">
                  <h4>Face shifting Detection based on Video Watermarking and PUF</h4>
                  <p>First Prize, 12th National College Student Information Security Contest (top 8%)</p>
                  <ul class="w3-ul" style="font-weight: 500;">
                    <li>Utilized OpenCV to apply video watermarking based on DCT (Discrete Cosine Transform)</li>
                    <li>Detected face shifting operation via NCC (Normalized Cross-Correlation) analysis of two watermark images extracted from videos before and after face shifting</li>
                    <li>Used Raspberry Pi to extract PUF (Physical Unclonable Function) information from SRAM to verify the video watermarking</li>
                    <li>Implemented a pipeline from video collection to video/image processing</li>
                  </ul>
              </div>
            </div>
          </div>

          <!--AWARDS-->
          <div id="awards" class="w3-container w3-container w3-margin-bottom-2 w3-cursive">
            <h2 class="w3-border-bottom w3-border-teal" style="border-width: 3px !important;">AWARDS</h2>
            <div class="w3-container w3-margin-top-2 w3-cursive">
              <ul class="w3-ul" style="font-weight: 500;">
                  <li>First Prize, 12th National College Student Information Security Contest (top 8%)</li>
                  <li>Excellent Student of Beijing University of Aeronautics and Astronautics (top 5%)</li>
                  <li>First Prize, Academic Excellence Award (top 5%)</li>
                  <li>Outstanding Student President of Beijing University of Aeronautics and Astronautics (top 4%)	</li>
              </ul>
            </div>
          </div>

          <!--CONTACT SECTION-->
          <div id="contact" class="w3-container w3-container w3-margin-bottom-2 w3-cursive">
            <h2 class="w3-border-bottom w3-border-teal" style="border-width: 3px !important;">CONTACT</h3>
            <div class="w3-margin-top-2" style="font-weight: 500;">
              <p>Address: Im oberen Werk 1, 66386 St. Ingbert, Germany</p>
              <p>E-mail: <a href="mailto:bihe.zhao@cispa.de" style="font-weight: 500;">bihe.zhao@cispa.de</a></li></p>
            </div>
          </div>
        <!-- </div> -->

        <!--FOOTER-->
        <!-- Footer. This section contains an ad for W3Schools Spaces. You can leave it to support us. -->
        <footer class="w3-container w3-border-top w3-center w3-margin-top-4">
          <p>© 2024 - Bihe Zhao</p>
        <!-- End footer -->
        </footer>

        <!--END OF CV SECTION-->
      </section>      
    </section>
    <script>
      // Function to toggle mobile navigation
      function toggleNavigation() {
        let nav = document.getElementById("mobile-nav");
        if (nav.classList.contains('w3-show')) {
          nav.classList.remove('w3-show');
        } else { 
          nav.classList.add('w3-show');
        }
      }
    </script>
    <script>
      // Script to load feather icons
      feather.replace()
    </script>
  </body>
</html>